{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/novdov/study/blob/master/Digit.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "GCHxe6vtkZ6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIDCISfFlPKk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DjM-Y9IWlrKV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IyYyR8Llli_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"drive/Colab Notebooks/train_digit.csv\")\n",
        "test = pd.read_csv(\"drive/Colab Notebooks/test_digit.csv\")\n",
        "train2 = train.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bDeVs3rxkqk1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        },
        "outputId": "c3889d9b-be7d-4e76-a662-7b5ca4b3cece"
      },
      "cell_type": "code",
      "source": [
        "y_train = train[\"label\"]\n",
        "train = train.drop(\"label\", axis=1)\n",
        "X_train = train\n",
        "\n",
        "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "y_train = pd.get_dummies(y_train)\n",
        "\n",
        "y_train = y_train.values\n",
        "\n",
        "yy = train2[\"label\"]\n",
        "\n",
        "yy_dummies = pd.get_dummies(yy)\n",
        "\n",
        "label = yy_dummies.columns\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01)) # 32개의 커널을 가진 컨볼루션 계층을 만듦\n",
        "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME') # 커널 슬라이딩 시 이미지의 가장 외곽에서 한 칸 밖으로 움직임\n",
        "L1 = tf.nn.relu(L1)\n",
        "# 풀링 계층\n",
        "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
        "                    padding='SAME')\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "L2 = tf.nn.relu(L2)\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], \n",
        "                    padding='SAME')\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
        "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
        "L3 = tf.matmul(L3, W3)\n",
        "L3 = tf.nn.relu(L3)\n",
        "L3 = tf.nn.dropout(L3, keep_prob)\n",
        "\n",
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# epoch = 50\n",
        "batch_size = 100\n",
        "\n",
        "train_size = X_train.shape[0]\n",
        "total_batch = int(train_size / batch_size)\n",
        "\n",
        "# 시간이 오래 걸려 colab에서 실행\n",
        "for epoch in range(100):\n",
        "    total_cost = 0\n",
        "    \n",
        "    idx = np.random.permutation(train_size)\n",
        "    X_random = X_train[idx]\n",
        "    y_random = y_train[idx]\n",
        "    \n",
        "    for i in range(total_batch):\n",
        "        batch_xs = X_random[i * total_batch:(i+1) * total_batch]\n",
        "        batch_ys = y_random[i * total_batch:(i+1) * total_batch]\n",
        "        \n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, \n",
        "                                                             Y: batch_ys, \n",
        "                                                             keep_prob: 0.7})\n",
        "        total_cost += cost_val        \n",
        "\n",
        "    print(\"Epoch: {:04d}\".format(epoch + 1), \n",
        "          \"Avg. cost: {:.3f}\".format(total_cost / total_batch))\n",
        "    \n",
        "print()\n",
        "print(\"Optimization completed!\")\n",
        "\n",
        "X_test = test.values.reshape(-1, 28, 28, 1)\n",
        "\n",
        "pred = tf.argmax(model, 1)\n",
        "\n",
        "prediction = sess.run(pred, feed_dict={X: X_test, keep_prob: 1})\n",
        "\n",
        "prediction = pd.Series(prediction, name=\"Label\")\n",
        "\n",
        "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), prediction],axis = 1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 Avg. cost: nan\n",
            "Epoch: 0002 Avg. cost: nan\n",
            "Epoch: 0003 Avg. cost: nan\n",
            "Epoch: 0004 Avg. cost: nan\n",
            "Epoch: 0005 Avg. cost: nan\n",
            "Epoch: 0006 Avg. cost: nan\n",
            "Epoch: 0007 Avg. cost: nan\n",
            "Epoch: 0008 Avg. cost: nan\n",
            "Epoch: 0009 Avg. cost: nan\n",
            "Epoch: 0010 Avg. cost: nan\n",
            "Epoch: 0011 Avg. cost: nan\n",
            "Epoch: 0012 Avg. cost: nan\n",
            "Epoch: 0013 Avg. cost: nan\n",
            "Epoch: 0014 Avg. cost: nan\n",
            "Epoch: 0015 Avg. cost: nan\n",
            "Epoch: 0016 Avg. cost: nan\n",
            "Epoch: 0017 Avg. cost: nan\n",
            "Epoch: 0018 Avg. cost: nan\n",
            "Epoch: 0019 Avg. cost: nan\n",
            "Epoch: 0020 Avg. cost: nan\n",
            "Epoch: 0021 Avg. cost: nan\n",
            "Epoch: 0022 Avg. cost: nan\n",
            "Epoch: 0023 Avg. cost: nan\n",
            "Epoch: 0024 Avg. cost: nan\n",
            "Epoch: 0025 Avg. cost: nan\n",
            "Epoch: 0026 Avg. cost: nan\n",
            "Epoch: 0027 Avg. cost: nan\n",
            "Epoch: 0028 Avg. cost: nan\n",
            "Epoch: 0029 Avg. cost: nan\n",
            "Epoch: 0030 Avg. cost: nan\n",
            "Epoch: 0031 Avg. cost: nan\n",
            "Epoch: 0032 Avg. cost: nan\n",
            "Epoch: 0033 Avg. cost: nan\n",
            "Epoch: 0034 Avg. cost: nan\n",
            "Epoch: 0035 Avg. cost: nan\n",
            "Epoch: 0036 Avg. cost: nan\n",
            "Epoch: 0037 Avg. cost: nan\n",
            "Epoch: 0038 Avg. cost: nan\n",
            "Epoch: 0039 Avg. cost: nan\n",
            "Epoch: 0040 Avg. cost: nan\n",
            "Epoch: 0041 Avg. cost: nan\n",
            "Epoch: 0042 Avg. cost: nan\n",
            "Epoch: 0043 Avg. cost: nan\n",
            "Epoch: 0044 Avg. cost: nan\n",
            "Epoch: 0045 Avg. cost: nan\n",
            "Epoch: 0046 Avg. cost: nan\n",
            "Epoch: 0047 Avg. cost: nan\n",
            "Epoch: 0048 Avg. cost: nan\n",
            "Epoch: 0049 Avg. cost: nan\n",
            "Epoch: 0050 Avg. cost: nan\n",
            "Epoch: 0051 Avg. cost: nan\n",
            "Epoch: 0052 Avg. cost: nan\n",
            "Epoch: 0053 Avg. cost: nan\n",
            "Epoch: 0054 Avg. cost: nan\n",
            "Epoch: 0055 Avg. cost: nan\n",
            "Epoch: 0056 Avg. cost: nan\n",
            "Epoch: 0057 Avg. cost: nan\n",
            "Epoch: 0058 Avg. cost: nan\n",
            "Epoch: 0059 Avg. cost: nan\n",
            "Epoch: 0060 Avg. cost: nan\n",
            "Epoch: 0061 Avg. cost: nan\n",
            "Epoch: 0062 Avg. cost: nan\n",
            "Epoch: 0063 Avg. cost: nan\n",
            "Epoch: 0064 Avg. cost: nan\n",
            "Epoch: 0065 Avg. cost: nan\n",
            "Epoch: 0066 Avg. cost: nan\n",
            "Epoch: 0067 Avg. cost: nan\n",
            "Epoch: 0068 Avg. cost: nan\n",
            "Epoch: 0069 Avg. cost: nan\n",
            "Epoch: 0070 Avg. cost: nan\n",
            "Epoch: 0071 Avg. cost: nan\n",
            "Epoch: 0072 Avg. cost: nan\n",
            "Epoch: 0073 Avg. cost: nan\n",
            "Epoch: 0074 Avg. cost: nan\n",
            "Epoch: 0075 Avg. cost: nan\n",
            "Epoch: 0076 Avg. cost: nan\n",
            "Epoch: 0077 Avg. cost: nan\n",
            "Epoch: 0078 Avg. cost: nan\n",
            "Epoch: 0079 Avg. cost: nan\n",
            "Epoch: 0080 Avg. cost: nan\n",
            "Epoch: 0081 Avg. cost: nan\n",
            "Epoch: 0082 Avg. cost: nan\n",
            "Epoch: 0083 Avg. cost: nan\n",
            "Epoch: 0084 Avg. cost: nan\n",
            "Epoch: 0085 Avg. cost: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0086 Avg. cost: nan\n",
            "Epoch: 0087 Avg. cost: nan\n",
            "Epoch: 0088 Avg. cost: nan\n",
            "Epoch: 0089 Avg. cost: nan\n",
            "Epoch: 0090 Avg. cost: nan\n",
            "Epoch: 0091 Avg. cost: nan\n",
            "Epoch: 0092 Avg. cost: nan\n",
            "Epoch: 0093 Avg. cost: nan\n",
            "Epoch: 0094 Avg. cost: nan\n",
            "Epoch: 0095 Avg. cost: nan\n",
            "Epoch: 0096 Avg. cost: nan\n",
            "Epoch: 0097 Avg. cost: nan\n",
            "Epoch: 0098 Avg. cost: nan\n",
            "Epoch: 0099 Avg. cost: nan\n",
            "Epoch: 0100 Avg. cost: nan\n",
            "\n",
            "Optimization completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R_tazVpAmCUt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"tensorflow_cnn.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RMsWa6opmF7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('tensorflow_cnn.csv', 'w') as f:\n",
        "    f.write(submission)\n",
        "\n",
        "files.download('example.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0TLuXBCDmc-F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('tensorflow_cnn.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6pW8LWsk5Zyu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}